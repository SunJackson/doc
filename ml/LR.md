**逻辑回归** 模型基于不同于 **线性回归** 的、关于因变量y和自变量x之间关系的假设。特别的，这两种模型
的区别可以在以下两个逻辑回归的特性中看出来：

1. 逻辑回归的条件分布y|x是伯努利分布，而线性回归的是高斯分布，因为逻辑回归的因变量是二元变量（0或1）。

2. 逻辑回归要预测的值是概率，因此要通过逻辑分布函数约束到（0,1）区间，因为逻辑回归预测的是某个输出值（0或1）的概率。

> 线性回归用于二分类时，首先想到下面这种形式，p=wx,p是属于类别的概率：
> 但是这时存在的问题是：
> 1）等式两边的取值范围不同，右边是负无穷到正无穷，左边是[0,1]，这个分类模型存在问题
> 2）实际中的很多问题，都是当x很小或很大时，对于因变量P的影响很小，当x达到中间某个阈值时，影响很大。即实际中很多问题，概率P与自变量并不是直线关系。
> 所以，上面这分类模型需要修整，怎么修正呢？统计学家们找到的一种方法是通过logit变换对因变量加以变换。


我们一开始希望输入变量x的线性组合能表示y=1的概率，但x的线性组合的取值范围为负无穷到正无穷，而概率为0到1，不过概率的对数几率可以是负无穷到正无穷，

log_odds(P(y=1∣x))=wo+w1x1+w2x2+...+wnxn。所以从这里可以推导出sigmoid函数。

![](https://img-blog.csdn.net/20180314110417378?watermark/2/text/Ly9ibG9nLmNzZG4ubmV0L3FxXzE5NjQ1MjY5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

