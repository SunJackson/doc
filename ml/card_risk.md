简介：自动调整超参数
===

调整机器学习模型的超参数有四种方法
1、手动（Manual） 依靠经验、猜测、直觉。很难达到准确结果
2、网格搜索（Grid Search）设置超参数值网格，并为每个组合训练模型并对验证结果进行评分，需要对网格中的所有参数进行训练验证，效率低
3、随机搜索（Random search）设置超参数值网格，随机组合参数训练模型并对结果进行打分。搜索迭代次数基于时间/资源设置
4、自动超参数调整（Automated Hyperparameter Tuning）使用诸如梯度下降，贝叶斯优化或进化算法之类的方法来进行最佳超参数的引导搜索。


贝叶斯优化入门
--
网格和随机搜索算法的问题在于这些是不知情的方法，因为它们不使用目标函数中不同超参数值以往产生的结果（记住目标函数接受的超参数并返回模型交叉验证分数）。
我们能够记录每组超参数和目标函数的结果，但是算法不会通过该信息选择下一个超参数值。
也就是说，如果我们能够得到过去的结果，那么我们应该用它们来推断出最有效的超参数值，并明智地选择下一个值来尝试花费更多的迭代来评估最有可能的值。
评估目标函数中的超参数非常耗时，贝叶斯优化算法的概念是通过基于先前结果去选择下一个超参数值来限制对评估函数的调用。
这使得算法花费更多时间来评估有希望的超参数值并且在超参数空间的低评分区域中花费更少的时间。

贝叶斯优化的四个部分
--
1、目标功能（Objective Function）接受输入（超参数）并返回分数以最小化或最大化（交叉验证分数）
2、域空间（Domain space）超参数范围
3、优化算法（Optimization Algorithm）用于构造代理函数的方法，并选择要评估的下一个值
4、结果（Results）超参数、分数键值对，用于构建代理函数算法

唯一的区别是，现在我们的目标函数将返回一个得分最小化（这只是优化领域的惯例），我们的域空间将是概率分布而不是超参数网格，优化算法将是一个知情的方法，
使用过去的结果来选择要评估的下一个超参数值。

Hyperopt
--
python开源库，使用Tree Parzen Estimator算法实现贝叶斯优化，以构建代理函数并选择下一个超参数值以在目标函数中进行评估。

Gradient Boosting Machine(GBM)
--
我们将使用梯度booosting机（GBM）作为我们的模型来调整LightGBM库。
GBM是我们对模型的选择，因为它对这些类型的问题表现得非常好（如排行榜上所示），并且因为性能在很大程度上取决于超参数值的选择。

Cross Validation with Early Stopping
--
与随机和网格搜索一样，我们将使用5倍交叉验证对训练数据评估每组超参数。
GBM模型将通过早期停止进行训练，其中评估器被添加到整体中，直到验证分数100次迭代没有变化（添加估算器）。

Dataset and Approach
--
我们将使用有限的数据部分 - 10000个训练数据和6000个测试数据。
这将允许notebook中的优化在合理的时间内完成。
稍后在notebook中，我将展示针对简化数据集的1000次贝叶斯超参数优化迭代的结果，然后我们将看到这些结果是否转换为完整数据集（来自此内核）。
这里开发的函数可以在任何数据集上运行或运行，或者与任何机器学习模型一起使用（只需对细节进行微小更改），并且使用较小的数据集将允许我们学习所有概念。
我目前正在完整数据集上运行500次贝叶斯超参数优化迭代，并在搜索完成时使结果可用。





